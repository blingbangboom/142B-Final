{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F1fEhcAwOJy2"
   },
   "source": [
    "# <font color=\"blue\"> Instructions on using Colab </font>\n",
    "\n",
    "1. You do not have permission to edit this original file. To start editing and save your changes, make a copy of the notebook and save it on your google drive (File-> Save a copy in Drive)(only one person in your group needs to do it). Then you can share this copy with your other teammates.\n",
    "2. Everyone in your team can edit this notebook. You can view revision history under File -> Revision history. (Note, however, that the revision histroy will be deleted at some point unless you \"pin\" the revision: File -> save and pin revision.)\n",
    "3. Please see the end of this notebook for submission instructions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u7wrzjx0FUZD"
   },
   "source": [
    "# Final Project (due Tue, June 10, 2025)\n",
    "\n",
    "The final group project has two parts\n",
    "\n",
    "- Part I is more similar to the HW projects, while\n",
    "- Part II requires some more independence. It involves learning and comprehending a method from a paper, and to then implement it.\n",
    "\n",
    "In contrast to the homework project, you are **not supposed to talk to anyone about the project outside of your group**. If you need help or advise, please contact us.\n",
    "\n",
    "Any violation of these rules, and more generally, any suspected academic misconduct will be reported to Office of Student Support and Student Judicial Affairs.\n",
    "\n",
    "Also be reminded about the [UC Davis code of academic conduct](https://ossja.ucdavis.edu/code-academic-conduct).\n",
    "\n",
    "\n",
    "### List all the group members here\n",
    "\n",
    "- 1\n",
    "  - Student ID: 916577012\n",
    "  - Student Name: Charles Zhang\n",
    "\n",
    "- 2\n",
    "  - Student ID:\n",
    "  - Student Name: Vivian Wong\n",
    "\n",
    "- 3\n",
    "  - Student ID: 919523380\n",
    "  - Student Name: Zi Zeng\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4MXYPV0-FUZI"
   },
   "source": [
    "- briefly describe the contribution of the individual group members here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rut1Zf9eFUZI"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yGHjLEBHFUZJ"
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from ipywidgets import interact\n",
    "from keras.datasets import mnist # pip install keras, pip install tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DNiHEndhFUZL"
   },
   "source": [
    "## Load the digit image data MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LoYRYffUFUZL"
   },
   "source": [
    "Each image is a digit with image size $28\\times 28$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PAgIEBESFUZM"
   },
   "outputs": [],
   "source": [
    "(train_X, train_y) = mnist.load_data()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AzYL6PNYFUZM"
   },
   "source": [
    "Because the original data set is very large, we only use a subset of the data set here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LVYkq3CzFUZN",
    "outputId": "74c52eda-2574-46ec-f983-c328053fe457"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5000, 784), (5000,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits_data = train_X[:5000].reshape(5000, -1)\n",
    "digits_target = train_y[:5000]\n",
    "digits_data.shape, digits_target.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V-lB2XaPFUZP"
   },
   "source": [
    "## Part I: Visualize the Principal Components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b-DtWAguFUZQ"
   },
   "source": [
    "### (1) Pick you favorite digit from 0-9. In part I, we will only look at images of your selected digit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Md83h29tFUZR"
   },
   "outputs": [],
   "source": [
    "# specify your favorite number\n",
    "num: int\n",
    "X = digits_data[digits_target == num]\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yaor0nl5FUZR"
   },
   "source": [
    "Let's show the mean image of your selected digit\n",
    "$\\bar{X} = \\sum_{i=1}^n X^{(i)}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qF6z2ZUDFUZS"
   },
   "outputs": [],
   "source": [
    "X_bar = X.mean(axis=0)\n",
    "plt.imshow(X_bar.reshape((28, 28)), cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8OxKiUo7FUZS"
   },
   "source": [
    "### (2) Visualize the 1st and 2nd principal component of your digit.\n",
    "Visualize $w_1$ and $w_2$. They are both in $\\mathbb{R}^{784}$ and can be visualized as images.\n",
    "\n",
    "They are the two top eigenvectors corresponding to the largest and second largest eigenvalues of the covariance matrix. Equivalently, they are right singular vectors corresponding to the largest and second largest singular value of the **centered** data.\n",
    "\n",
    "Therefore, you can use SVD or eigenvalue decomposition, or use the `PCA` method in `scikit-learn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZxGKyB79FUZT"
   },
   "outputs": [],
   "source": [
    "def show_principal_components(k = 2):\n",
    "    # calculate the first kth principal components, defined as W: np.ndarray\n",
    "    # the ith of column of W is the ith principal component\n",
    "    ##### your code starts here #####\n",
    "\n",
    "\n",
    "\n",
    "    ##### your code ends here #####\n",
    "\n",
    "    fig, ax = plt.subplots(1, k + 1)\n",
    "    ax[0].imshow(X_bar.reshape((28, 28)), cmap=\"gray\")\n",
    "    ax[0].set_title(\"mean\")\n",
    "    ax[0].axis(\"off\")\n",
    "    for i in range(k):\n",
    "        ax[i+1].imshow(W[:, i].reshape((28, 28)), cmap=\"gray\")\n",
    "        ax[i+1].set_title(f\"{i+1}th PC\")\n",
    "        ax[i+1].axis(\"off\")\n",
    "    plt.show(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9uHNIIQUFUZT"
   },
   "outputs": [],
   "source": [
    "show_principal_components(k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i1e6lv-pFUZU"
   },
   "outputs": [],
   "source": [
    "interact(show_principal_components)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FzorWcnBFUZU"
   },
   "source": [
    "### (3) Visualize the projection scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MM0fltUeFUZU"
   },
   "source": [
    "Make a 2D scatter plot of the first two principal components (the projection scores) $Z_1$, $Z_2 \\in \\mathbb{R}^n$, where $n$ is the number of data points in the data matrix $X$. Put the first PC score $Z_1$ on the $x$-axis.\n",
    "\n",
    "Make a $5 \\times 5$ \"uniform\" grid based on the marginal quantile of the scores. That is, the grid is spanned by\n",
    "\n",
    "- ($\\min(Z_1)$, 25th quantile of $Z_1$, median($Z_1$), 75th quantile of $Z_1$, $\\max(Z_1)$)\n",
    "  \n",
    "and\n",
    "\n",
    "- ($\\min(Z_2)$, 25th quantile of $Z_2$, median($Z_2$), 75th quantile of $Z_2$, $\\max(Z_2)$)\n",
    "\n",
    "There are 25 cells in the grid. For each cell, mark the data point **closest to the midpoint**. So you will have 25 marked data points.\n",
    "\n",
    "Hint: use `np.quantile` and `np.meshgrid`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8EvdR39uFUZV"
   },
   "outputs": [],
   "source": [
    "##### your code starts here #####\n",
    "\n",
    "\n",
    "\n",
    "# hint\n",
    "# plt.plot(Z[:,0], Z[:,1], '.')\n",
    "# X_grid = np.quantile(Z[:,0], [0, 0.25, 0.5, 0.75, 1])\n",
    "# Y_grid = np.quantile(Z[:,1], [0, 0.25, 0.5, 0.75, 1])\n",
    "# xv, yv = np.meshgrid(X_grid, Y_grid)\n",
    "\n",
    "\n",
    "##### your code ends here #####\n",
    "plt.xlabel(\"1st PC\")\n",
    "plt.ylabel(\"2nd PC\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XdGj7bJPFUZV"
   },
   "source": [
    "Next make a figure with 4 $\\times$ 4 subplots, each one displays the original image corresponding to the marked data point in the previous plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YaiNDfo5FUZV"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(5, 5)\n",
    "\n",
    "##### your code starts here #####\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##### your code ends here #####\n",
    "\n",
    "plt.show(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lS2nEP7bFUZW"
   },
   "source": [
    "Do you see any pattern here? Can you explain it with the principal components you displayed in (3)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lT_6U2OKFUZW"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h-PcFEd7FUZW"
   },
   "source": [
    "### (4) How does the singular value of $X$ change with $k$?\n",
    "First, make a plot of the singular values against $k$. Name the x-axis as \"k\", and the y-axis as \"singular value\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lBaZjCUeFUZW"
   },
   "outputs": [],
   "source": [
    "##### your code starts here #####\n",
    "\n",
    "\n",
    "\n",
    "##### your code ends here #####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9y8Sgky8FUZW"
   },
   "source": [
    "You should see some type of an elbow shape, meaning a few of the largest principal components already explain a large proportion of variance in the image.\n",
    "\n",
    "For comparison, let's now add another curve. For each image in $X$, randomly shuffle the entries. The image should look like random noise after the shuffling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BfL2KLhyFUZX"
   },
   "outputs": [],
   "source": [
    "X_shuffle = X.copy()\n",
    "##### your code starts here #####\n",
    "\n",
    "\n",
    "\n",
    "##### your code ends here #####\n",
    "plt.imshow(X_shuffle[0].reshape((28, 28)), cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZZ9o8pmUFUZX"
   },
   "source": [
    "Then add another \"singular value vs k\" curve for `X_shuffle`, with different color. Add a label for each curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nOJ5QtGJFUZX"
   },
   "outputs": [],
   "source": [
    "##### your code starts here #####\n",
    "\n",
    "\n",
    "\n",
    "##### your code ends here #####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v-eolbV2jnCE"
   },
   "source": [
    "Discuss what you see:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "efvVb585jnCE"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GOkW6TVTFUZX"
   },
   "source": [
    "### (5) Kernel Density Estimation -- tuning the `bandwidth`\n",
    "\n",
    "We now apply PCA to the entire data set with $ k = 50$. `Z` is now the projection scores with shape (n, 50)\n",
    "\n",
    "- Compute the kernel density estimator using `sklearn.neighbors.KernelDensity`. Here, let's simply use the Gaussian kernel and the Euclidean distance, and explore the effect of the `bandwidth` parameter. Discover the difference between using two different bandwidths, 0.1 and 200.\n",
    "\n",
    "- Draw 16 new sample points from each fitted density using `KernelDensity.sample` (for comparison purpose, please use the same value for `random_state` for both bandwidths). Of course, these samples are in the space of projection scores. Use `pca.inverse_transform` to reconstruct digit images from these samples. Compare the sample digits drawn from density fitted with large bandwidth and small bandwidth. What are the differences? Could you give some intuitive explanations why you are seeing overlapping digits when `bandwidth` is large?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k8VyPjQUFUZY"
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KernelDensity\n",
    "\n",
    "k = 50\n",
    "pca = PCA(n_components=k)\n",
    "Z = pca.fit_transform(digits_data)\n",
    "\n",
    "def sample_digits(bandwidth: float = 1.0, n_samples:int = 16) -> np.ndarray:\n",
    "    ##### your code starts here #####\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ##### your code ends here #####\n",
    "    return new_digits # its shape should be (n_samples, 784)\n",
    "\n",
    "new_digits_1 = sample_digits(bandwidth=0.1, n_samples=16).reshape((4, 4, -1))\n",
    "new_digits_2 = sample_digits(bandwidth=200, n_samples=16).reshape((4, 4, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SrqnJX8FFUZY"
   },
   "outputs": [],
   "source": [
    "def show_digits(new_digits: np.ndarray):\n",
    "    '''\n",
    "    new_digits have shape (4, 4, 784)\n",
    "    '''\n",
    "    fig, ax = plt.subplots(4, 4, subplot_kw=dict(xticks=[], yticks=[]))\n",
    "\n",
    "    ##### your code starts here #####\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ##### your code ends here #####\n",
    "\n",
    "    plt.show(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_D6A4gtoFUZY"
   },
   "outputs": [],
   "source": [
    "show_digits(new_digits_1)\n",
    "show_digits(new_digits_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qR-B7K2JFUZY"
   },
   "source": [
    "Use `sklearn.model_selection.GridSearchCV` to select the best bandwidth. Refit the model with the selected bandwidth, then draw another sample of 16 digits using that density. You can search for bandwidth within the choices `np.logspace(-1, 3, 20)`.\n",
    "\n",
    "`GridSearchCV` (by default) uses the estimator's `score` method to evaluation performance on the test folds. In the case of `KernelDensity`, `score()` gives the log-likelihood of the test data in the estimated density. (Here it is the likelihood under the Gaussian mixture model (GMM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4QEkDpatFUZZ"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "##### your code starts here #####\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##### your code ends here #####\n",
    "\n",
    "new_digits_cv = sample_digits(bandwidth=cv_selected_bandwidth, n_samples=16).reshape((4, 4, -1))\n",
    "show_digits(new_digits_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_9vujkWmJsD6"
   },
   "source": [
    "Note that your CV-selected bandwidth, which maximizes the likelihood on the test folds, does not necessarily look better than the previous choices. Could you (intuitively) explain why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F3yKWZFnjnCF"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eMY_260oFUZZ"
   },
   "source": [
    "## Part II: Select the number of clusters using the *Gap statistic* ([Tibshirani et al., 2001b](hastie.su.domains/Papers/gap.pdf)).\n",
    "\n",
    "This paper provides a statistical procedure to formalize the heuristic of the \"elbow method\", by looking at the gap between the change in within-cluster dispersion and its \"expected\" version.\n",
    "\n",
    "The algorithm is described in detail in section 4 in the paper.\n",
    "\n",
    "$$ \\widehat{k} = \\arg \\min_k \\{k\\vert \\mathrm{Gap}(k) \\ge \\mathrm{Gap}(k + 1) - s_{k+1}\\}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1ZjXvfynFUZZ"
   },
   "source": [
    "### (a) Implement the algorithm.\n",
    "\n",
    "Note the following:\n",
    "- Your algorithm should take a general `X: np.ndarray` as input, with shape $(n, p)$.\n",
    "\n",
    "- There are two choices of reference distribution mentioned in Section 4. You need to implement both of them. For example, in your function you can specify a parameter called `need_PCA`, if `need_PCA==True`, draw $B$ samples from the reference distribution (a). Otherwise, draw $B$ samples from the reference distribution (b). (By default, set $B = 50$.)\n",
    "\n",
    "- For efficiency, you can specify an upper limit for $k$. Namely, only calculate Gap($k$) for $ 1 \\le k \\le$ `kmax`. If none of the considered $k$ satisfy $ \\mathrm{Gap}(k) \\ge \\mathrm{Gap}(k + 1) - s_{k+1}$, then output a result that represents $k>$ `kmax` - 1, such as `np.inf` or `None`.\n",
    "\n",
    "- Besides the selected $k$, you should also be able to output plots like in Fig. 2 of the [paper](hastie.su.domains/Papers/gap.pdf). Our data `X` in general has $p \\ge 2$. Instead of the scatter plot (a) in Fig. 2, make a plot of $\\textrm{Gap}(k) - \\textrm{Gap}(k + 1) + s_{k+1}$ against $k$, so that $\\hat{k}$ will be the smallest $k$ that gives a positive value of that curve. (You can add an horizontal dashed line at $y=0$)\n",
    "\n",
    "Some suggestions for making the plots:\n",
    "- Introduce a parameter named `need_plot` to control whether to make the plots, or simply output the selected $\\hat{k}$.\n",
    "- Use `plt.subplots((2,2))`. If you want to adjust the overall figure size, you can set e.g. `figsize=(10, 10)` in `subplot()`\n",
    "- To show the error bars like in Fig 2 (d), you can use `plt.errorbar`.\n",
    "- Specify what is your $x$-axis and what is your $y$-axis for each subplot. Make a title if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RiYtjY3gFUZ6"
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# This is an example of what your algorithm can look like.\n",
    "# Of course you can define other helper functions, or even rewrite this function entirely from scratch,\n",
    "# as long as you can output the selected k, and you can (optionally) output the plots.\n",
    "def select_k_by_Gap_statistic(X: np.ndarray, kmax: int = 20, B: int = 50, need_PCA: bool = False, need_plot: bool =True) -> int:\n",
    "    '''\n",
    "    returns the number of clusters k selected by the Gap statistic. If the selected k is larger than kmax, return None.\n",
    "    X has shape (n, p); n is the sample size; p is the number of features.\n",
    "    kmax is maximum k whose Gap(k) will be computed\n",
    "    B is the number of copies from the reference distribution\n",
    "    need_PCA means whether to use the reference distribution (1) or (2)\n",
    "    if need_plot = True, make the required plots. You can use plt.subplots().\n",
    "    It is recommended to set a seed for generating the reference distributions,\n",
    "    so that you can always reproduce the same results.\n",
    "    '''\n",
    "    ##### your code starts here #####\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uBlaU1REFUZ7"
   },
   "source": [
    "### (b) Apply the algorithm to the data containing only your favourite digit.\n",
    "\n",
    "Use the original data as input. Then apply the algorithm, using two different reference distributions, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dfoyeqLVFUZ7"
   },
   "source": [
    "Following is some example code. Feel free to modify it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BrV60Qi9FUZ8"
   },
   "outputs": [],
   "source": [
    "X = digits_data[digits_target == num]\n",
    "B = 100\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q1AJAUQFFUZ8"
   },
   "outputs": [],
   "source": [
    "select_k_by_Gap_statistic(X, kmax=20, B=B, need_PCA=True, need_plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iPEL11g-FUZ8"
   },
   "outputs": [],
   "source": [
    "select_k_by_Gap_statistic(X, kmax=20, B=B, need_PCA=False, need_plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kxdJbNUEFUZ9"
   },
   "source": [
    "Answer the following questions:\n",
    "- Before running the algorithm, what is your guess of the output $\\hat{k}$? Is the selected $\\hat{k}$ very different from what you expect?\n",
    "- What differences do you see between outcomes using the two types of reference distributions? If their selected $\\hat{k}$ are very different, could you provide some explanations?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "anqYQKQWGpu_"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mp7fXSOdVfkX"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bw_EuArzFUZ9"
   },
   "source": [
    "### (c) We now apply the algorithm to the entire data set. But this time we will first transform the data by PCA.\n",
    "For example, we first project the data to 10 principal component scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vIl1nGRCFUZ9"
   },
   "outputs": [],
   "source": [
    "pca_complete_dataset = PCA(n_components=10)\n",
    "pca_complete_dataset.fit(digits_data)\n",
    "X = pca_complete_dataset.transform(digits_data)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NFJcqJRCFUZ-"
   },
   "outputs": [],
   "source": [
    "select_k_by_Gap_statistic(X, kmax=20, B=B, need_PCA=True, need_plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wIl0fZmBFUZ-"
   },
   "outputs": [],
   "source": [
    "select_k_by_Gap_statistic(X, kmax=20, B=B, need_PCA=False, need_plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "imhP6VRoFUZ-"
   },
   "source": [
    "Note that now we obtain exactly the same results when using the two different reference distributions. Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e7kh_FcYFUZ_"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cxr1a9G8FUZ_"
   },
   "source": [
    "### (d) Explore how the PCA projection dimension $d$ affects the $\\hat k$ selected by the Gap statistic.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5as3-mccFUZ_"
   },
   "source": [
    "For each PCA projection dimension $d$ in `[1, 5, 10, 15, 20, 25, 40, 60]`, apply the Gap statistic and find the selected $\\hat{k}$. Make a plot of $\\hat{k}$ against $d$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MBL3d2TMFUZ_"
   },
   "outputs": [],
   "source": [
    "# example code. You may modify it.\n",
    "d_list = [1, 5, 10, 15, 20, 25, 40, 60]\n",
    "k_hat_list = []\n",
    "for d in d_list:\n",
    "    pca_complete_dataset = PCA(n_components=d)\n",
    "    pca_complete_dataset.fit(digits_data)\n",
    "    X = pca_complete_dataset.transform(digits_data[:1000, ]) # reduce the sample size for efficiency\n",
    "    k_hat = select_k_by_Gap_statistic(X, kmax=20, B=50, need_PCA=False, need_plot=False)\n",
    "    k_hat_list.append(k_hat)\n",
    "    print(f\"PCA with {d} components. Selected k: {k_hat}\")\n",
    "\n",
    "plt.plot(d_list, k_hat_list, 'x-')\n",
    "plt.xlabel(r'$d$')\n",
    "plt.ylabel(r'$\\hat k$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "onC5BZXSFUaA"
   },
   "source": [
    "Intuitively explain why you see $\\hat{k}$ change with $d$ in this way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rAzWv2AeFUaA"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YugjI4AVFUaB"
   },
   "source": [
    "### (e) Repeat (d) on the projection scores of your favorite digit. Again, make a plot of $\\hat{k}$ against $d$.\n",
    "\n",
    "Consider $d$ in `[2, 3, 5, 10, 15, 20, 25, 40]`.  Note that we use the PCA model *fitted on the entire data set*, but only use the projection scores of your favorite digit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AT_OeZdRFUaB"
   },
   "outputs": [],
   "source": [
    "# example code. You may modify it.\n",
    "d_list = [2, 3, 5, 10, 15, 20, 25, 40]\n",
    "k_hat_list = []\n",
    "for d in d_list:\n",
    "    pca_complete_dataset = PCA(n_components=d)\n",
    "    pca_complete_dataset.fit(digits_data)\n",
    "    X = pca_complete_dataset.transform(digits_data[digits_target == num, ]) # reduce the sample size for efficiency\n",
    "    k_hat = select_k_by_Gap_statistic(X, kmax=20, B=50, need_PCA=False, need_plot=False)\n",
    "    k_hat_list.append(k_hat)\n",
    "    print(f\"PCA with {d} components. Selected k: {k_hat}\")\n",
    "\n",
    "plt.plot(d_list, k_hat_list, 'x-')\n",
    "plt.xlabel(r'$d$')\n",
    "plt.ylabel(r'$\\hat k$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y6Xfu3lHFUaC"
   },
   "source": [
    "Intuitively explain why you see $\\hat{k}$ change with $d$ in this way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SW7MFoAqFUaC"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jJL9NCJqmYca"
   },
   "source": [
    "# <font color=\"blue\"> Submission Instructions</font>\n",
    "\n",
    "## if you choose to mainly work on Colab (recommended)\n",
    "1. (If you haven't done so) File -> Save a copy in Drive.\n",
    "2. Select Runtime -> Run All. This will run all the cells in order, and will take up to several minutes. <font color='red'>You will not get any grade if you don't follow this step strictly. This is to make sure that your code is executing the code without an error message.</font>\n",
    "3. Make sure your outputs are generated correctly. Save again.\n",
    "4. Share the file with\n",
    "   - TA: mxsun@ucdavis.edu (Commenter)\n",
    "5. You can choose from one of the following.\n",
    "   - Select File -> Print, and your browser will allow you to save/print to pdf.\n",
    "   - Select File -> Download -> Download .ipynb. Then follow Step 3 below. The pdf generate in the way below may be a little prettier as it shows the code blocks more distinctly.\n",
    "6. Look at the PDF file and make sure all your solutions are there, displayed correctly.\n",
    "7. Submit your PDF on Gradescope.\n",
    "\n",
    "## if you choose to work locally\n",
    "1. Click the Save button at the top of the Jupyter Notebook.\n",
    "2. Select Cell -> Run All. This will run all the cells in order, and will take up to several minutes. <font color='red'>You will not get any grade if you don't follow this step strictly. This is to make sure that your code is executing the code without an error message.</font>\n",
    "3. Once you've re-run everything, select File -> Download as -> PDF via LaTeX (You would need to install [pandoc](https://pandoc.org/installing.html) and latex. See the link for instructions.) **Or, a simpler way is to select File -> Download as -> html**. But because gradescope only accepts PDF, you can use the web browser (e.g. Chrome) feature of print to PDF. Make sure that when doing so, place the html under the same folder with all you figures.\n",
    "4. Look at the PDF file and make sure all your solutions are there, displayed correctly.\n",
    "5. Submit your PDF on Gradescope.\n",
    "7. Upload your final ipynb file (with all your solutions and all the outputs) to your google drive, open it with google colab, and then share it with\n",
    "   - TA: mxsun@ucdavis.edu (Commenter)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
